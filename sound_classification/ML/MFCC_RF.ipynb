{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a193322",
   "metadata": {},
   "source": [
    "### 1. Baseline\n",
    "* original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed2e9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-398.98666382  113.03168488  -11.29673195   27.68769264    3.6051693\n",
      "   11.02839375   -4.29368401    7.7390089     3.64515638    5.37020397\n",
      "   -3.23544407    9.0578289    -4.63530731]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MFCC = 13 # num of MFCC features\n",
    "\n",
    "mfcc_folder = '../dataset/mfcc_features'\n",
    "np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "# prepare data\n",
    "X = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "y = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "# each group is one video\n",
    "filenames = set()\n",
    "groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "# load form directory\n",
    "for i, file in enumerate(np_file):\n",
    "    mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "    X[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "    # 0: normal driving, 1: car crash\n",
    "    label = 0 if int(file.split('_')[0]) < 5 else 1\n",
    "    y[i] = label    \n",
    "    filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "    # search with set to find unique value\n",
    "    if filename not in filenames:\n",
    "        filenames.add(filename)\n",
    "        groups[i] = len(filenames)\n",
    "    else:\n",
    "        groups[i] = list(filenames).index(filename)\n",
    "\n",
    "print(X[0])  # print the first sample\n",
    "print(y[0])  # print the label of the first sample\n",
    "print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b8f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "import random\n",
    "random.seed(0)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b717bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "group_kfold = GroupKFold(n_splits=5) # 5-fold\n",
    "print(group_kfold.get_n_splits(X, y, groups))  # print number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f2e9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.17073170731707318\n",
      "Precision: 1.0\n",
      "Recall: 0.11688311688311688\n",
      "F1 Score: 0.20930232558139536\n",
      "ROC AUC: 0.761038961038961\n",
      "Confusion Matrix:\n",
      "[[ 5  0]\n",
      " [68  9]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9512195121951219\n",
      "Precision: 0.75\n",
      "Recall: 0.9\n",
      "F1 Score: 0.8181818181818182\n",
      "ROC AUC: 0.9812500000000001\n",
      "Confusion Matrix:\n",
      "[[69  3]\n",
      " [ 1  9]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9878048780487805\n",
      "Precision: 1.0\n",
      "Recall: 0.9\n",
      "F1 Score: 0.9473684210526315\n",
      "ROC AUC: 0.9805555555555555\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 1  9]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9024390243902439\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.8\n",
      "F1 Score: 0.6666666666666666\n",
      "ROC AUC: 0.9402777777777778\n",
      "Confusion Matrix:\n",
      "[[66  6]\n",
      " [ 2  8]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7926829268292683\n",
      "Precision: 0.34615384615384615\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5142857142857142\n",
      "ROC AUC: 0.9490106544901066\n",
      "Confusion Matrix:\n",
      "[[56 17]\n",
      " [ 0  9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    # print([train_index])\n",
    "    clf.fit(X[train_index], y[train_index])\n",
    "    # testing\n",
    "    y_pred = clf.predict(X[test_index])\n",
    "    y_pred_prob = clf.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf.predict(X[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_prob)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52da1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 1.5761 seconds\n",
      "Average time per batch: 15.76 ms\n",
      "Average time per sample: 0.19 ms\n",
      "Inference speed: 5202.75 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477bb04",
   "metadata": {},
   "source": [
    "2. DataAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d27d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-270.81295776  -15.02099133   38.02788925   13.21731472   10.0347805\n",
      "    4.48674297    3.34693432    3.60442758    4.46276379    3.18351889\n",
      "    2.26930118    1.81936967    0.86694759]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def read_dataAug(mfcc_folder):\n",
    "    np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "    # prepare data\n",
    "    X_aug = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "    y_aug = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "    # each group is one video\n",
    "    filenames = set()\n",
    "    groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "    # load form directory\n",
    "    for i, file in enumerate(np_file):\n",
    "        mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "        X_aug[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "        # 0: normal driving, 1: car crash\n",
    "        label = 0 if int(file.split('_')[1]) < 5 else 1\n",
    "        y_aug[i] = label    \n",
    "        filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "        # search with set to find unique value\n",
    "        if filename not in filenames:\n",
    "            filenames.add(filename)\n",
    "            groups[i] = len(filenames)\n",
    "        else:\n",
    "            groups[i] = list(filenames).index(filename)\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mfcc_folder = '../dataset/aug_mfcc_features'\n",
    "    X_aug, y_aug = read_dataAug(mfcc_folder)\n",
    "    print(X_aug[0])  # print the first sample\n",
    "    print(y_aug[0])  # print the label of the first sample\n",
    "    print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1613a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.25609756097560976\n",
      "Precision: 1.0\n",
      "Recall: 0.2077922077922078\n",
      "F1 Score: 0.34408602150537637\n",
      "ROC AUC: 0.7298701298701299\n",
      "Confusion Matrix:\n",
      "[[ 5  0]\n",
      " [61 16]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9878048780487805\n",
      "Precision: 1.0\n",
      "Recall: 0.9\n",
      "F1 Score: 0.9473684210526315\n",
      "ROC AUC: 1.0\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 1  9]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.975609756097561\n",
      "Precision: 1.0\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8888888888888888\n",
      "ROC AUC: 0.9986111111111111\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 2  8]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9634146341463414\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8421052631578947\n",
      "ROC AUC: 0.9611111111111111\n",
      "Confusion Matrix:\n",
      "[[71  1]\n",
      " [ 2  8]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8292682926829268\n",
      "Precision: 0.391304347826087\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5625\n",
      "ROC AUC: 0.9596651445966514\n",
      "Confusion Matrix:\n",
      "[[59 14]\n",
      " [ 0  9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_aug = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    # print(train_index)\n",
    "    X_combined = np.vstack((X[train_index].copy(), X_aug.copy()))\n",
    "    y_combined = np.hstack((y[train_index].copy(), y_aug.copy()))\n",
    "    \n",
    "    clf_aug.fit(X_combined, y_combined)\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_aug.predict(X[test_index])\n",
    "    y_pred_proba = clf_aug.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y_combined, clf_aug.predict(X_combined))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8bbfee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 1.9151 seconds\n",
      "Average time per batch: 19.15 ms\n",
      "Average time per sample: 0.23 ms\n",
      "Inference speed: 4281.84 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0801f",
   "metadata": {},
   "source": [
    "3. tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a587243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# 使用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=seed)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a248f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.43902439024390244\n",
      "Precision: 0.9696969696969697\n",
      "Recall: 0.4155844155844156\n",
      "F1 Score: 0.5818181818181818\n",
      "ROC AUC: 0.6961038961038961\n",
      "Confusion Matrix:\n",
      "[[ 4  1]\n",
      " [45 32]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9024390243902439\n",
      "Precision: 0.5555555555555556\n",
      "Recall: 1.0\n",
      "F1 Score: 0.7142857142857143\n",
      "ROC AUC: 0.9451388888888889\n",
      "Confusion Matrix:\n",
      "[[64  8]\n",
      " [ 0 10]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9512195121951219\n",
      "Precision: 0.875\n",
      "Recall: 0.7\n",
      "F1 Score: 0.7777777777777778\n",
      "ROC AUC: 0.9840277777777777\n",
      "Confusion Matrix:\n",
      "[[71  1]\n",
      " [ 3  7]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8414634146341463\n",
      "Precision: 0.42105263157894735\n",
      "Recall: 0.8\n",
      "F1 Score: 0.5517241379310345\n",
      "ROC AUC: 0.9375\n",
      "Confusion Matrix:\n",
      "[[61 11]\n",
      " [ 2  8]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7195121951219512\n",
      "Precision: 0.23076923076923078\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.34285714285714286\n",
      "ROC AUC: 0.7739726027397261\n",
      "Confusion Matrix:\n",
      "[[53 20]\n",
      " [ 3  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_tsne = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X_tsne, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    clf_tsne.fit(X_tsne[train_index], y[train_index])\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_tsne.predict(X_tsne[test_index])\n",
    "    y_pred_proba = clf_tsne.predict_proba(X_tsne[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf_tsne.predict(X_tsne[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70951c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 1.6883 seconds\n",
      "Average time per batch: 16.88 ms\n",
      "Average time per sample: 0.21 ms\n",
      "Inference speed: 4857.00 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = tsne.fit_transform(X[test_index])\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
