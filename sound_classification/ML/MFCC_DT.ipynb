{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a193322",
   "metadata": {},
   "source": [
    "### 1. Baseline\n",
    "* original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed2e9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-398.98666382  113.03168488  -11.29673195   27.68769264    3.6051693\n",
      "   11.02839375   -4.29368401    7.7390089     3.64515638    5.37020397\n",
      "   -3.23544407    9.0578289    -4.63530731]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MFCC = 13 # num of MFCC features\n",
    "\n",
    "mfcc_folder = '../dataset/mfcc_features'\n",
    "np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "# prepare data\n",
    "X = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "y = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "# each group is one video\n",
    "filenames = set()\n",
    "groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "# load form directory\n",
    "for i, file in enumerate(np_file):\n",
    "    mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "    X[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "    # 0: normal driving, 1: car crash\n",
    "    label = 0 if int(file.split('_')[0]) < 5 else 1\n",
    "    y[i] = label    \n",
    "    filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "    # search with set to find unique value\n",
    "    if filename not in filenames:\n",
    "        filenames.add(filename)\n",
    "        groups[i] = len(filenames)\n",
    "    else:\n",
    "        groups[i] = list(filenames).index(filename)\n",
    "\n",
    "print(X[0])  # print the first sample\n",
    "print(y[0])  # print the label of the first sample\n",
    "print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b8f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b717bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "group_kfold = GroupKFold(n_splits=5) # 5-fold\n",
    "print(group_kfold.get_n_splits(X, y, groups))  # print number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f2e9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.5233644859813084\n",
      "Precision: 1.0\n",
      "Recall: 0.32894736842105265\n",
      "F1 Score: 0.49504950495049505\n",
      "ROC AUC: 0.6644736842105263\n",
      "Confusion Matrix:\n",
      "[[31  0]\n",
      " [51 25]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8552631578947368\n",
      "Precision: 0.5\n",
      "Recall: 0.9090909090909091\n",
      "F1 Score: 0.6451612903225806\n",
      "ROC AUC: 0.8776223776223776\n",
      "Confusion Matrix:\n",
      "[[55 10]\n",
      " [ 1 10]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.6710526315789473\n",
      "Precision: 0.25\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.3902439024390244\n",
      "ROC AUC: 0.7653399668325042\n",
      "Confusion Matrix:\n",
      "[[43 24]\n",
      " [ 1  8]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7631578947368421\n",
      "Precision: 0.34615384615384615\n",
      "Recall: 0.9\n",
      "F1 Score: 0.5\n",
      "ROC AUC: 0.8212121212121213\n",
      "Confusion Matrix:\n",
      "[[49 17]\n",
      " [ 1  9]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.84\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.8\n",
      "F1 Score: 0.5714285714285714\n",
      "ROC AUC: 0.823076923076923\n",
      "Confusion Matrix:\n",
      "[[55 10]\n",
      " [ 2  8]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    clf.fit(X[train_index], y[train_index])\n",
    "    # testing\n",
    "    y_pred = clf.predict(X[test_index])\n",
    "    y_pred_proba = clf.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf.predict(X[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52da1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.0286 seconds\n",
      "Average time per batch: 0.29 ms\n",
      "Average time per sample: 0.00 ms\n",
      "Inference speed: 262520.28 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748e399",
   "metadata": {},
   "source": [
    "2. Data augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3065783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-270.81295776  -15.02099133   38.02788925   13.21731472   10.0347805\n",
      "    4.48674297    3.34693432    3.60442758    4.46276379    3.18351889\n",
      "    2.26930118    1.81936967    0.86694759]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def read_dataAug(mfcc_folder):\n",
    "    np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "    # prepare data\n",
    "    X_aug = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "    y_aug = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "    # each group is one video\n",
    "    filenames = set()\n",
    "    groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "    # load form directory\n",
    "    for i, file in enumerate(np_file):\n",
    "        mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "        X_aug[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "        # 0: normal driving, 1: car crash\n",
    "        label = 0 if int(file.split('_')[1]) < 5 else 1\n",
    "        y_aug[i] = label    \n",
    "        filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "        # search with set to find unique value\n",
    "        if filename not in filenames:\n",
    "            filenames.add(filename)\n",
    "            groups[i] = len(filenames)\n",
    "        else:\n",
    "            groups[i] = list(filenames).index(filename)\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mfcc_folder = '../dataset/aug_mfcc_features'\n",
    "    X_aug, y_aug = read_dataAug(mfcc_folder)\n",
    "    print(X_aug[0])  # print the first sample\n",
    "    print(y_aug[0])  # print the label of the first sample\n",
    "    print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb9c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.5327102803738317\n",
      "Precision: 1.0\n",
      "Recall: 0.34210526315789475\n",
      "F1 Score: 0.5098039215686274\n",
      "ROC AUC: 0.6710526315789473\n",
      "Confusion Matrix:\n",
      "[[31  0]\n",
      " [50 26]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.881578947368421\n",
      "Precision: 0.5555555555555556\n",
      "Recall: 0.9090909090909091\n",
      "F1 Score: 0.6896551724137931\n",
      "ROC AUC: 0.893006993006993\n",
      "Confusion Matrix:\n",
      "[[57  8]\n",
      " [ 1 10]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7105263157894737\n",
      "Precision: 0.27586206896551724\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.42105263157894735\n",
      "ROC AUC: 0.7877280265339967\n",
      "Confusion Matrix:\n",
      "[[46 21]\n",
      " [ 1  8]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7894736842105263\n",
      "Precision: 0.38461538461538464\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5555555555555556\n",
      "ROC AUC: 0.8787878787878788\n",
      "Confusion Matrix:\n",
      "[[50 16]\n",
      " [ 0 10]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7866666666666666\n",
      "Precision: 0.35\n",
      "Recall: 0.7\n",
      "F1 Score: 0.4666666666666667\n",
      "ROC AUC: 0.75\n",
      "Confusion Matrix:\n",
      "[[52 13]\n",
      " [ 3  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_aug = tree.DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    X_combined = np.vstack((X[train_index].copy(), X_aug.copy()))\n",
    "    y_combined = np.hstack((y[train_index].copy(), y_aug.copy()))\n",
    "    \n",
    "    clf_aug.fit(X_combined, y_combined)\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_aug.predict(X[test_index])\n",
    "    y_pred_proba = clf_aug.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y_combined, clf_aug.predict(X_combined))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "850718d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.0333 seconds\n",
      "Average time per batch: 0.33 ms\n",
      "Average time per sample: 0.00 ms\n",
      "Inference speed: 225314.47 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c262f5",
   "metadata": {},
   "source": [
    "3. tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "754cdc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# 使用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=seed)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad54bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.616822429906542\n",
      "Precision: 0.972972972972973\n",
      "Recall: 0.47368421052631576\n",
      "F1 Score: 0.6371681415929203\n",
      "ROC AUC: 0.7207130730050934\n",
      "Confusion Matrix:\n",
      "[[30  1]\n",
      " [40 36]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9473684210526315\n",
      "Precision: 0.8181818181818182\n",
      "Recall: 0.8181818181818182\n",
      "F1 Score: 0.8181818181818182\n",
      "ROC AUC: 0.8937062937062937\n",
      "Confusion Matrix:\n",
      "[[63  2]\n",
      " [ 2  9]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.631578947368421\n",
      "Precision: 0.1935483870967742\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.3\n",
      "ROC AUC: 0.6467661691542288\n",
      "Confusion Matrix:\n",
      "[[42 25]\n",
      " [ 3  6]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8421052631578947\n",
      "Precision: 0.4375\n",
      "Recall: 0.7\n",
      "F1 Score: 0.5384615384615384\n",
      "ROC AUC: 0.7818181818181819\n",
      "Confusion Matrix:\n",
      "[[57  9]\n",
      " [ 3  7]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8266666666666667\n",
      "Precision: 0.4117647058823529\n",
      "Recall: 0.7\n",
      "F1 Score: 0.5185185185185185\n",
      "ROC AUC: 0.7730769230769231\n",
      "Confusion Matrix:\n",
      "[[55 10]\n",
      " [ 3  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_tsne = tree.DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X_tsne, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    clf_tsne.fit(X_tsne[train_index], y[train_index])\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_tsne.predict(X_tsne[test_index])\n",
    "    y_pred_proba = clf_tsne.predict_proba(X_tsne[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf_tsne.predict(X_tsne[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "811b25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.0339 seconds\n",
      "Average time per batch: 0.34 ms\n",
      "Average time per sample: 0.00 ms\n",
      "Inference speed: 221463.08 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = tsne.fit_transform(X[test_index])\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49312d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
