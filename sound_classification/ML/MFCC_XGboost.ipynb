{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a193322",
   "metadata": {},
   "source": [
    "### 1. Baseline\n",
    "* original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2e9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-398.98666382  113.03168488  -11.29673195   27.68769264    3.6051693\n",
      "   11.02839375   -4.29368401    7.7390089     3.64515638    5.37020397\n",
      "   -3.23544407    9.0578289    -4.63530731]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MFCC = 13 # num of MFCC features\n",
    "\n",
    "mfcc_folder = '../dataset/mfcc_features'\n",
    "np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "# prepare data\n",
    "X = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "y = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "# each group is one video\n",
    "filenames = set()\n",
    "groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "# load form directory\n",
    "for i, file in enumerate(np_file):\n",
    "    mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "    X[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "    # 0: normal driving, 1: car crash\n",
    "    label = 0 if int(file.split('_')[0]) < 5 else 1\n",
    "    y[i] = label    \n",
    "    filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "    # search with set to find unique value\n",
    "    if filename not in filenames:\n",
    "        filenames.add(filename)\n",
    "        groups[i] = len(filenames)\n",
    "    else:\n",
    "        groups[i] = list(filenames).index(filename)\n",
    "\n",
    "print(X[0])  # print the first sample\n",
    "print(y[0])  # print the label of the first sample\n",
    "print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b8f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "import random\n",
    "random.seed(0)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b717bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "group_kfold = GroupKFold(n_splits=5) # 5-fold\n",
    "print(group_kfold.get_n_splits(X, y, groups))  # print number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2e9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.24390243902439024\n",
      "Precision: 1.0\n",
      "Recall: 0.20512820512820512\n",
      "F1 Score: 0.3404255319148936\n",
      "ROC AUC: 0.9358974358974359\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [62 16]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9390243902439024\n",
      "Precision: 0.6428571428571429\n",
      "Recall: 1.0\n",
      "F1 Score: 0.782608695652174\n",
      "ROC AUC: 0.9863013698630136\n",
      "Confusion Matrix:\n",
      "[[68  5]\n",
      " [ 0  9]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7439024390243902\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.43243243243243246\n",
      "ROC AUC: 0.821917808219178\n",
      "Confusion Matrix:\n",
      "[[53 20]\n",
      " [ 1  8]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.926829268292683\n",
      "Precision: 0.6923076923076923\n",
      "Recall: 0.8181818181818182\n",
      "F1 Score: 0.75\n",
      "ROC AUC: 0.9731113956466069\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 2  9]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.7195121951219512\n",
      "Precision: 0.23076923076923078\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.34285714285714286\n",
      "ROC AUC: 0.8569254185692542\n",
      "Confusion Matrix:\n",
      "[[53 20]\n",
      " [ 3  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    clf.fit(X[train_index], y[train_index])\n",
    "    # testing\n",
    "    y_pred = clf.predict(X[test_index])\n",
    "    y_pred_prob = clf.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf.predict(X[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_prob)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52da1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.1061 seconds\n",
      "Average time per batch: 1.06 ms\n",
      "Average time per sample: 0.01 ms\n",
      "Inference speed: 77277.53 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10483a68",
   "metadata": {},
   "source": [
    "2. DataAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92224eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-270.81295776  -15.02099133   38.02788925   13.21731472   10.0347805\n",
      "    4.48674297    3.34693432    3.60442758    4.46276379    3.18351889\n",
      "    2.26930118    1.81936967    0.86694759]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def read_dataAug(mfcc_folder):\n",
    "    np_file = os.listdir(mfcc_folder)\n",
    "\n",
    "    # prepare data\n",
    "    X_aug = np.zeros((len(np_file), MFCC)) # (n_samples, n_features)\n",
    "    y_aug = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "    # each group is one video\n",
    "    filenames = set()\n",
    "    groups = np.zeros(len(np_file), dtype=int)  # (n_samples, )\n",
    "\n",
    "    # load form directory\n",
    "    for i, file in enumerate(np_file):\n",
    "        mfcc = np.load(os.path.join(mfcc_folder, file))\n",
    "        X_aug[i] = mfcc.mean(axis=1)    # (MFCC, )\n",
    "        # 0: normal driving, 1: car crash\n",
    "        label = 0 if int(file.split('_')[1]) < 5 else 1\n",
    "        y_aug[i] = label    \n",
    "        filename = file[file.find('_') + 1:file.rfind('_')]  # segment is the second part of the filename\n",
    "        # search with set to find unique value\n",
    "        if filename not in filenames:\n",
    "            filenames.add(filename)\n",
    "            groups[i] = len(filenames)\n",
    "        else:\n",
    "            groups[i] = list(filenames).index(filename)\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mfcc_folder = '../dataset/aug_mfcc_features'\n",
    "    X_aug, y_aug = read_dataAug(mfcc_folder)\n",
    "    print(X_aug[0])  # print the first sample\n",
    "    print(y_aug[0])  # print the label of the first sample\n",
    "    print(groups[0])  # print the group of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376eb59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 0.9986449864498645\n",
      "Validation Accuracy: 0.36585365853658536\n",
      "Precision: 1.0\n",
      "Recall: 0.3333333333333333\n",
      "F1 Score: 0.5\n",
      "ROC AUC: 0.9743589743589743\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [52 26]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 0.994579945799458\n",
      "Validation Accuracy: 0.926829268292683\n",
      "Precision: 0.6\n",
      "Recall: 1.0\n",
      "F1 Score: 0.75\n",
      "ROC AUC: 0.9893455098934552\n",
      "Confusion Matrix:\n",
      "[[67  6]\n",
      " [ 0  9]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.997289972899729\n",
      "Validation Accuracy: 0.9024390243902439\n",
      "Precision: 0.5333333333333333\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.6666666666666666\n",
      "ROC AUC: 0.9604261796042618\n",
      "Confusion Matrix:\n",
      "[[66  7]\n",
      " [ 1  8]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9932249322493225\n",
      "Validation Accuracy: 0.926829268292683\n",
      "Precision: 0.6923076923076923\n",
      "Recall: 0.8181818181818182\n",
      "F1 Score: 0.75\n",
      "ROC AUC: 0.9846350832266326\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 2  9]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9986449864498645\n",
      "Validation Accuracy: 0.8658536585365854\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.5925925925925926\n",
      "ROC AUC: 0.9254185692541856\n",
      "Confusion Matrix:\n",
      "[[63 10]\n",
      " [ 1  8]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_aug = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    X_combined = np.vstack((X[train_index].copy(), X_aug.copy()))\n",
    "    y_combined = np.hstack((y[train_index].copy(), y_aug.copy()))\n",
    "    \n",
    "    clf_aug.fit(X_combined, y_combined)\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_aug.predict(X[test_index])\n",
    "    y_pred_proba = clf_aug.predict_proba(X[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y_combined, clf_aug.predict(X_combined))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893b3854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.1191 seconds\n",
      "Average time per batch: 1.19 ms\n",
      "Average time per sample: 0.01 ms\n",
      "Inference speed: 68822.65 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = X[test_index]\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_aug.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8088f",
   "metadata": {},
   "source": [
    "3. tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d748c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# 使用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=seed)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe0a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.4024390243902439\n",
      "Precision: 1.0\n",
      "Recall: 0.3717948717948718\n",
      "F1 Score: 0.5420560747663551\n",
      "ROC AUC: 0.9631410256410255\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [49 29]]\n",
      "\n",
      "Fold 1:\n",
      "Training Accuracy: 0.9725609756097561\n",
      "Validation Accuracy: 0.8902439024390244\n",
      "Precision: 0.5\n",
      "Recall: 0.7777777777777778\n",
      "F1 Score: 0.6086956521739131\n",
      "ROC AUC: 0.949771689497717\n",
      "Confusion Matrix:\n",
      "[[66  7]\n",
      " [ 2  7]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9847560975609756\n",
      "Validation Accuracy: 0.7926829268292683\n",
      "Precision: 0.3181818181818182\n",
      "Recall: 0.7777777777777778\n",
      "F1 Score: 0.45161290322580644\n",
      "ROC AUC: 0.8462709284627093\n",
      "Confusion Matrix:\n",
      "[[58 15]\n",
      " [ 2  7]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9725609756097561\n",
      "Validation Accuracy: 0.8536585365853658\n",
      "Precision: 0.47058823529411764\n",
      "Recall: 0.7272727272727273\n",
      "F1 Score: 0.5714285714285714\n",
      "ROC AUC: 0.9161331626120358\n",
      "Confusion Matrix:\n",
      "[[62  9]\n",
      " [ 3  8]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9786585365853658\n",
      "Validation Accuracy: 0.9024390243902439\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.6\n",
      "ROC AUC: 0.919330289193303\n",
      "Confusion Matrix:\n",
      "[[68  5]\n",
      " [ 3  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "clf_tsne = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "# fit data (using k-fold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X_tsne, y, groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    # training\n",
    "    clf_tsne.fit(X_tsne[train_index], y[train_index])\n",
    "    \n",
    "    # testing\n",
    "    y_pred = clf_tsne.predict(X_tsne[test_index])\n",
    "    y_pred_proba = clf_tsne.predict_proba(X_tsne[test_index])[:, 1]  # probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Training Accuracy: {accuracy_score(y[train_index], clf_tsne.predict(X_tsne[train_index]))}\")\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y[test_index], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y[test_index], y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y[test_index], y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y[test_index], y_pred_proba)}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y[test_index], y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b7eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Measuring inference time...\n",
      "Total time for 100 iterations: 0.0919 seconds\n",
      "Average time per batch: 0.92 ms\n",
      "Average time per sample: 0.01 ms\n",
      "Inference speed: 89192.37 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Get a subset of test data for inference\n",
    "# For this example, I'll use the last fold from the GroupKFold as test data\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    if i == 4:  # Use the last fold as test data\n",
    "        test_data = tsne.fit_transform(X[test_index])\n",
    "        break\n",
    "\n",
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "for _ in range(10):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time...\")\n",
    "n_iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    _ = clf_tsne.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_batch = total_time / n_iterations\n",
    "avg_time_per_sample = total_time / (n_iterations * len(test_data))\n",
    "\n",
    "print(f\"Total time for {n_iterations} iterations: {total_time:.4f} seconds\")\n",
    "print(f\"Average time per batch: {avg_time_per_batch*1000:.2f} ms\")\n",
    "print(f\"Average time per sample: {avg_time_per_sample*1000:.2f} ms\")\n",
    "print(f\"Inference speed: {n_iterations * len(test_data) / total_time:.2f} samples/second\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
